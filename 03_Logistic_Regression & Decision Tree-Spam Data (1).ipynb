{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Read about Log. regression here \n",
    "#  https://en.wikipedia.org/wiki/Logistic_regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from random import random\n",
    "from pyspark import SparkContext\n",
    "\n",
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.linalg import SparseVector\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD,LogisticRegressionModel, LogisticRegressionWithLBFGS, SVMWithSGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4054 bkg318\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "port = 4040 + hash(os.getcwd().split(\"/\")[2])%200\n",
    "config = pyspark.SparkConf().set('spark.executor.memory', '512M')\\\n",
    "         .set('spark.cores.max', '10')\\\n",
    "         .set('spark.port.maxRetries','200')\\\n",
    "         .set('spark.ui.port', port)    \n",
    "print port,     os.getcwd().split(\"/\")[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext(appName=\"Logistic Regression\", master='spark://polyp1:7077',conf = config )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFile = '/scratch/ISE495/lab6/data/enron.libsvm'\n",
    "dictionary = '/scratch/ISE495/lab6/data/dictionary.dat'\n",
    "IDFileMapping = '/scratch/ISE495/lab6/data/fileids.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'14174 0 2354:1 4930:1 16751:2 24305:2 29014:1 49781:1 50345:1 68800:1 71782:1 89812:1 108348:1 114434:1 116870:1 136310:1 148421:1']\n"
     ]
    }
   ],
   "source": [
    "data = sc.textFile(dataFile)\n",
    "data1 = sc.textFile(dictionary)\n",
    "data2 = sc.textFile(IDFileMapping)\n",
    "\n",
    "print data.take(1)\n",
    "# print data1.count()\n",
    "# print data2.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have 157309 uniq words \n"
     ]
    }
   ],
   "source": [
    "# read file \"dictionary\" and create a hashTable \"dic\" where KEY=ID and Value = word, e.g. dic[0]=fawn\n",
    "dic={} \n",
    "with open(dictionary,'rU') as f:\n",
    "    for l in f:\n",
    "        d = l.strip().split(\",\")\n",
    "        dic[int(d[0])]=d[1]\n",
    "d = len(dic)  #TODO: size of dictionary\n",
    "print \"we have %d uniq words \"%d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.linalg import SparseVector\n",
    "\n",
    "from pyspark.mllib.feature import HashingTF\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD, LogisticRegressionWithLBFGS, SVMWithSGD, NaiveBayes\n",
    "from pyspark.mllib.tree import DecisionTree, GradientBoostedTrees, RandomForest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "\n",
    "# read file \"dataFile\" and create a data  (fix this template code)\n",
    "# dataFeatures=[]\n",
    "# dataLabels=[]\n",
    "# with open(dataFile,'rU') as f:\n",
    "#     for line in f:\n",
    "#         line= line.replace(':',' ')\n",
    "#         data=line.split(' ')\n",
    "#         label = int(data.pop(1))*2 - 1\n",
    "#         #print label\n",
    "#         data.pop(0)\n",
    "#         ids=[int(data[x]) for x in range(0,len(data)) if x % 2==0]\n",
    "#         #print ids\n",
    "#         vals=[int(data[x]) for x in range(0,len(data)) if x % 2!=0]\n",
    "#         #print vals\n",
    "#         vals=vals/np.linalg.norm(vals)\n",
    "#         #print vals\n",
    "#         features = SparseVector(d,ids,vals)\n",
    "#         #print features\n",
    "#         dataFeatures+=[features]\n",
    "#         dataLabels+=[label]\n",
    "#     reutun LabeledPoint(dataLabels,dataFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'14174 0 2354:1 4930:1 16751:2 24305:2 29014:1 49781:1 50345:1 68800:1 71782:1 89812:1 108348:1 114434:1 116870:1 136310:1 148421:1',\n",
       " u'32720 1 128:1 137:1 203:1 975:1 2354:3 2675:1 5702:1 5845:1 6244:1 7515:1 11289:1 13682:1 13963:1 20991:1 21229:1 21779:1 21867:1 21872:1 23186:1 26852:1 27145:2 27704:1 28082:2 29959:1 30171:2 31087:1 31889:1 32720:1 34182:1 36102:1 36182:1 36565:1 36566:1 36591:2 39098:1 41188:1 46618:1 46969:1 47934:1 49551:1 49781:2 50575:2 51860:1 54655:2 55866:1 56324:3 56470:1 58658:1 59008:1 60121:1 60667:1 62775:1 62792:5 65227:1 68004:1 68245:1 68530:2 70199:1 71782:2 74994:1 75959:1 75972:1 80089:1 80241:1 80948:1 84072:1 84787:2 86528:1 86858:1 87285:1 97018:1 100864:1 101332:2 103095:1 103379:1 103506:1 106451:1 107293:1 112087:1 112509:1 112844:1 113425:1 113787:1 114029:2 114434:1 114848:1 116357:1 119133:1 122662:1 123601:1 124257:1 130124:1 130983:1 131255:1 132990:1 134321:1 134837:1 138265:1 144733:1 154296:1 157122:1']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LabeledPoint(0.0, (157309,[2354,4930,16751,24305,29014,49781,50345,68800,71782,89812,108348,114434,116870,136310,148421],[0.2182178902359924,0.2182178902359924,0.4364357804719848,0.4364357804719848,0.2182178902359924,0.2182178902359924,0.2182178902359924,0.2182178902359924,0.2182178902359924,0.2182178902359924,0.2182178902359924,0.2182178902359924,0.2182178902359924,0.2182178902359924,0.2182178902359924]))]\n"
     ]
    }
   ],
   "source": [
    "def parseData(line):\n",
    "    line= line.replace(':',' ')\n",
    "    data=line.split(' ')\n",
    "    label = int(data.pop(1))*2 - 1\n",
    "    if label==-1:\n",
    "        label=0\n",
    "        #print label\n",
    "    data.pop(0)\n",
    "    ids=[int(data[x]) for x in range(0,len(data)) if x % 2==0]\n",
    "        #print ids\n",
    "    vals=[int(data[x]) for x in range(0,len(data)) if x % 2!=0]\n",
    "        #print vals\n",
    "    vals=vals/np.linalg.norm(vals)\n",
    "        #print vals\n",
    "    #dic{ids} = vals \n",
    "    features = SparseVector(d,ids,vals)\n",
    "    return LabeledPoint(label,features)\n",
    "\n",
    "parsedData = data.map(parseData)\n",
    "print parsedData.take(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LabeledPoint(0.0, (157309,[2354,4930,16751,24305,29014,49781,50345,68800,71782,89812,108348,114434,116870,136310,148421],[0.2182178902359924,0.2182178902359924,0.4364357804719848,0.4364357804719848,0.2182178902359924,0.2182178902359924,0.2182178902359924,0.2182178902359924,0.2182178902359924,0.2182178902359924,0.2182178902359924,0.2182178902359924,0.2182178902359924,0.2182178902359924,0.2182178902359924]))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# this will split randomly the data 60% for training and 40% for testing\n",
    "trainingData, testData = parsedData.randomSplit( [0.8, 0.2] , seed = 11L)\n",
    "trainingData.cache()\n",
    "testData.cache()\n",
    "print trainingData.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(model):\n",
    "    predictions = model.predict(testData.map(lambda x: x.features))\n",
    "    labels_and_preds = testData.map(lambda x: x.label).zip(predictions)\n",
    "    accuracy = labels_and_preds.filter(lambda x: float(x[0]) == float(x[1])).count() / float(testData.count())\n",
    "    return (accuracy*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/classification.py:313: UserWarning: Deprecated in 2.0.0. Use ml.classification.LogisticRegression or LogisticRegressionWithLBFGS.\n",
      "  \"Deprecated in 2.0.0. Use ml.classification.LogisticRegression or \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91.76628810520025"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LogisticRegressionWithSGD\n",
    "algo = LogisticRegressionWithSGD()\n",
    "model = algo.train(trainingData)\n",
    "score(model)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.75971309025702"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LogisticRegressionWithLBFGS()\n",
    "algo = LogisticRegressionWithLBFGS()\n",
    "model = algo.train(trainingData)\n",
    "score(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DecisionTree()\n",
    "algo = DecisionTree()\n",
    "model = algo.trainClassifier(trainingData, 2,{},impurity='entropy', maxDepth=5, maxBins=8)\n",
    "score(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find more inforamtion about parameteres at:\n",
    "# # https://spark.apache.org/docs/2.1.1/api/python/pyspark.mllib.html#pyspark.mllib.classification.LogisticRegressionWithLBFGS\n",
    "# model = LogisticRegressionWithLBFGS.train(trainingData, iterations=15, regParam=0.0001, regType='l2', intercept=True)#, numClasses=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluating the model on training data\n",
    "# labelsAndPreds = trainingData.map(lambda p: (p.label, model.predict(p.features)))\n",
    "# trainErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(trainingData.count())\n",
    "# print(\"Training Error = \" + str(trainErr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelsAndPreds1 = testData.map(lambda p: (p.label, model.predict(p.features)))\n",
    "# testErr = labelsAndPreds1.filter(lambda (v, p): v != p).count() / float(testData.count())\n",
    "# print(\"Testing Error = \" + str(testErr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.predict([1.0,817.180406555498,12106.1347003149])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, create a copy of this jupyter notebook and run Log. Regression on the \"SPAM\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameter search:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The effect of normalization:\n",
    "If dont normalize the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpretation of the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorical Features in Decision Trees (DT):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
