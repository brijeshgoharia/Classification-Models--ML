{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Read about Log. regression here \n",
    "#  https://en.wikipedia.org/wiki/Logistic_regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from random import random\n",
    "from pyspark import SparkContext\n",
    "\n",
    "import sys\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4054 bkg318\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "port = 4040 + hash(os.getcwd().split(\"/\")[2])%200\n",
    "config = pyspark.SparkConf().set('spark.executor.memory', '512M')\\\n",
    "         .set('spark.cores.max', '2')\\\n",
    "         .set('spark.port.maxRetries','200')\\\n",
    "         .set('spark.ui.port', port)    \n",
    "print port,     os.getcwd().split(\"/\")[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext(appName=\"Logistic Regression\", master='spark://polyp1:7077',conf = config )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.textFile(\"/scratch/ISE495/lab6_ML/ISLR.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseData(line):\n",
    "    data = line.strip().split(\",\")\n",
    "    default = data[1]\n",
    "    if default=='\"No\"':\n",
    "        label=0\n",
    "    else:\n",
    "        label=1\n",
    "        \n",
    "    student = data[2]\n",
    "    if student == '\"No\"':\n",
    "        student =0\n",
    "    else:\n",
    "        student =1\n",
    "    features=(float(data[3]),float(data[4]), student)  \n",
    "    \n",
    "    # you should fill this function\n",
    "    \n",
    "    return LabeledPoint(label,features)\n",
    "\n",
    "parsedData = data.map(parseData)\n",
    "\n",
    "# this will split randomly the data 60% for training and 40% for testing\n",
    "trainingData, testData = parsedData.randomSplit( [0.6, 0.4] , seed = 11L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error = 0.0350819129571\n"
     ]
    }
   ],
   "source": [
    "# Find more inforamtion about parameteres at:\n",
    "# https://spark.apache.org/docs/2.1.1/api/python/pyspark.mllib.html#pyspark.mllib.classification.LogisticRegressionWithLBFGS\n",
    "model = LogisticRegressionWithLBFGS.train(trainingData, iterations=10, regParam=0.0001, regType='l2', intercept=True)\n",
    "\n",
    "# Evaluating the model on training data\n",
    "labelsAndPreds = trainingData.map(lambda p: (p.label, model.predict(p.features)))\n",
    "trainErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(trainingData.count())\n",
    "print(\"Training Error = \" + str(trainErr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.0535759413697\n",
      "Accuracy = 94.642405863\n"
     ]
    }
   ],
   "source": [
    "trainErr_test = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(testData.count())\n",
    "#print(\"Testing Error = \" + str(trainErr_test))\n",
    "\n",
    "Accuracy=(1-trainErr_test)*100\n",
    "print('Test Error = ' + str(trainErr_test))\n",
    "print ('Accuracy = ' + str(Accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have used regParam=0.0001, try to use different values and plot training and testing \n",
    "# error as a function of regParam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now, create a copy of this jupyter notebook and run Log. Regression on the \"SPAM\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
